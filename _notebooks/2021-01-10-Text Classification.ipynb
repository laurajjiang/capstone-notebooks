{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "azdata_cell_guid": "13509f6f-44c1-47f7-98b4-591aa1f1c062"
   },
   "source": [
    "# Text Classification  \n",
    "\n",
    "> Chapter 1 - learn about using a neural network to classify text using sentiment (positive or negative).\n",
    "\n",
    "- toc: true\n",
    "- branch: master\n",
    "- badges: false\n",
    "- comments: false\n",
    "- annotations: true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "azdata_cell_guid": "51edfc0b-4fb6-4fef-9736-bd551e6e1fc1"
   },
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "azdata_cell_guid": "66b3dda0-aef7-42e3-adaa-8b0e2772f915"
   },
   "source": [
    "Text classification is the process of assigning tags or categories to text according to its content. It’s one of the fundamental tasks in natural language processing.\n",
    "\n",
    "The text we wanna classify is given as input to an algorithm, the algorithm will then analyze the text’s content, and then categorize the input as one of the tags or categories previously given.\n",
    "\n",
    "**Input → Classifying Algorithm → Classification of Input**\n",
    "\n",
    "Real life examples:\n",
    "\n",
    "- Sentiment analysis: how does the writer of the sentence feel about what they are writing about, do they think positively or negatively of the subject? Ex. restaurant reviews topic labeling: given sentences and a set of topics, which topic does this sentence fall under? Ex. is this essay about history? Math? etc? spam detection Ex. Email filtering: is this email a real important email or spam?\n",
    "\n",
    "Example. A restaurant wants to evaluate their ratings but don’t want to read through all of them. Therefore, they wanna use a computer algorithm to do all their work. They simply want to know if the customer’s review is positive or negative.\n",
    "\n",
    "Here’s an example of a customer’s review and a simple way an algorithm could classify their review.\n",
    "\n",
    "Input: “The food here was too salty and too expensive”\n",
    "\n",
    "Algorithm: Goes through every word in the sentence and counts how many positive words and how many negative words are in the sentence.\n",
    "\n",
    "```\n",
    "    “The, food, here, was, too, and” are all neutral words\n",
    "\n",
    "    “Salty, expensive” are negative words.\n",
    "\n",
    "    Negative words: 2\n",
    "    Positive words: 0\n",
    "```\n",
    "\n",
    "Classification: Negative Review, because there are more negative words (2) than positive (0).\n",
    "\n",
    "However, this algorithm obviously doesn’t work in a lot of cases.\n",
    "\n",
    "For example, “The food here was good, not expensive and not salty” would be classified as negative but it’s actually a positive review.\n",
    "\n",
    "Language and text can get very complicated which makes creating these algorithms difficult. Some things that make language difficult could be words that have multiple meanings, negation words (words such as not), slang, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "azdata_cell_guid": "e2e811b1-609e-4a92-97fa-c61508274bb4"
   },
   "source": [
    "# Set up data and imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "azdata_cell_guid": "d5e32e42-b3b6-4282-999d-acf05252fb06"
   },
   "source": [
    "## Library imports\n",
    "\n",
    "This section of code is to import any necessary Python libraries that we'll need for the rest of this notebook. Some packages may need to be installed since they are not built in to Python3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "azdata_cell_guid": "6305a379-9ec8-4ba3-94e4-e54c9ef30f38"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<script src=\"https://d3js.org/d3.v3.min.js\" charset=\"utf-8\"></script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# collapse-hide\n",
    "# !pip3 install seaborn\n",
    "# !pip3 install plotly --user\n",
    "# !pip3 install sklearn\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import string\n",
    "from scipy import sparse\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import plotly.offline as py\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "import plotly.graph_objs as go\n",
    "init_notebook_mode(connected = True)\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from html import escape\n",
    "from IPython.core.display import display, HTML\n",
    "from string import Template\n",
    "from sklearn.metrics import classification_report\n",
    "import json\n",
    "\n",
    "HTML('<script src=\"https://d3js.org/d3.v3.min.js\" charset=\"utf-8\"></script>')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "azdata_cell_guid": "9a1685b0-0396-4ed6-a19f-a43bf2293859"
   },
   "source": [
    "## Getting our data \n",
    "\n",
    "Below is a definition of getData, a basic function to pull from the `trainingSet.txt` and `testSet.txt`. The data that we're using for this example is a set of reviews written by users on Yelp, classified as positive (1) or negative (0). \n",
    "\n",
    "We open the file, create temporary arrays, and pull from the file line by line.\n",
    "\n",
    "Open the cell if you'd like to peek into what the function looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "azdata_cell_guid": "73b2409b-c9e0-4fc0-b5c3-93d0d70e9fc5"
   },
   "outputs": [],
   "source": [
    "# collapse-hide\n",
    "# Our two files that contain our data, split up into a training set and a testing set.\n",
    "\n",
    "trainingFile = \"dataset/trainingSet.txt\"\n",
    "testingFile = \"dataset/testSet.txt\"\n",
    "\n",
    "def getData(fileName):\n",
    "    f = open(fileName)\n",
    "    file = f.readlines()\n",
    "\n",
    "    sentences = []\n",
    "    sentiments = []\n",
    "\n",
    "    for line in file:\n",
    "        sentence, sentiment = line.split('\\t')\n",
    "        sentences.append(sentence.strip())\n",
    "        sentiments.append(int(sentiment.strip())) # Sentiment in {0,1}\n",
    "\n",
    "    return sentences, np.array(sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "azdata_cell_guid": "ea307c06-6f6f-4e2b-9dad-d353d5d63211",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get data from the training and testing files using the getData function defined above\n",
    "\n",
    "trainingSentences, trainingLabels = getData(trainingFile)\n",
    "testingSentences, testingLabels = getData(testingFile) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "azdata_cell_guid": "9859f856-7986-472f-a18b-a176e955b7e8"
   },
   "source": [
    "Let's take a peek at what this data looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "azdata_cell_guid": "0e6f77c6-9cee-4b4d-a474-9cd47d057bf7",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample sentences:\n",
      "['Wow... Loved this place.',\n",
      " 'Not tasty and the texture was just nasty.',\n",
      " 'Stopped by during the late May bank holiday off Rick Steve recommendation '\n",
      " 'and loved it.',\n",
      " 'The selection on the menu was great and so were the prices.',\n",
      " 'Now I am getting angry and I want my damn pho.',\n",
      " \"Honeslty it didn't taste THAT fresh.)\",\n",
      " 'The potatoes were like rubber and you could tell they had been made up ahead '\n",
      " 'of time being kept under a warmer.',\n",
      " 'The fries were great too.',\n",
      " 'A great touch.',\n",
      " 'Service was very prompt.']\n",
      "Corresponding sentiments:\n",
      "[1, 0, 1, 1, 0, 0, 0, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "#collapse-hide \n",
    "\n",
    "f = open(trainingFile)\n",
    "file = f.readlines()\n",
    "\n",
    "sentences = []\n",
    "sentiments = []\n",
    "\n",
    "for line in file:\n",
    "    sentence, sentiment = line.split('\\t')\n",
    "    sentences.append(sentence.strip())\n",
    "    sentiments.append(int(sentiment.strip())) \n",
    "    \n",
    "print(\"Sample sentences:\")\n",
    "pprint(sentences[:10]) \n",
    "print(\"Corresponding sentiments:\")\n",
    "pprint(sentiments[:10]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "azdata_cell_guid": "38a166de-5063-4638-8c15-19a57e742c68"
   },
   "source": [
    "## Pre-processing our data \n",
    "\n",
    "We need to modify these sentences by tokenizing them into individual strings (word by word) so that we can feed our model individual words and their associated sentiment (negative / positive)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "azdata_cell_guid": "a0954a22-336d-469c-a32d-835d7329ba76"
   },
   "outputs": [],
   "source": [
    "def preProcess(sentences):\n",
    "\n",
    "    def cleanText(text):\n",
    "        # Make lower case\n",
    "        text = text.lower()\n",
    "\n",
    "        # Replace non-text characters with spaces\n",
    "        nonText = string.punctuation + (\"\")\n",
    "        text = text.translate(str.maketrans(nonText, ' ' * (len(nonText))))\n",
    "\n",
    "        # Split sentences into individual words - tokenize\n",
    "        words = text.split()\n",
    "\n",
    "        return words\n",
    "\n",
    "    return list(map(cleanText, sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "azdata_cell_guid": "ad995853-5e2e-4ee7-a51f-b1a9a56561e0"
   },
   "outputs": [],
   "source": [
    "# Process both the training and testing tokens.\n",
    "\n",
    "trainingTokens = preProcess(trainingSentences)\n",
    "testingTokens = preProcess(testingSentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "azdata_cell_guid": "55a58566-03ca-4f68-b161-d53318d8b80a"
   },
   "source": [
    "Let's look at what these tokenized sentences look like now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "azdata_cell_guid": "1e0deff3-61e4-4ad9-b470-e32366be70fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training tokens:\n",
      "[['wow', 'loved', 'this', 'place'],\n",
      " ['not', 'tasty', 'and', 'the', 'texture', 'was', 'just', 'nasty']]\n",
      "Testing tokens:\n",
      "[['crust', 'is', 'not', 'good'],\n",
      " ['would', 'not', 'go', 'back'],\n",
      " ['i', 'was', 'shocked', 'because', 'no', 'signs', 'indicate', 'cash', 'only']]\n"
     ]
    }
   ],
   "source": [
    "#collapse-hide\n",
    "print(\"Training tokens:\")\n",
    "pprint(trainingTokens[:2]) \n",
    "print(\"Testing tokens:\")\n",
    "pprint(testingTokens[:3]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "azdata_cell_guid": "b88a3dd5-4436-454c-8ce9-3ada65a8f614"
   },
   "source": [
    "## Vectorizing our data\n",
    "\n",
    "Now that we have our sentences tokenized, notice how our training tokens are nested arrays. We want to pull them out of nested arrays and into just one general vocabulary list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "azdata_cell_guid": "7536bef9-a077-4690-8efe-a380f9ca0874"
   },
   "outputs": [],
   "source": [
    "#collapse-hide\n",
    "\n",
    "def getVocab(sentences):\n",
    "    vocab = set()\n",
    "    for sentence in sentences:\n",
    "        for word in sentence:\n",
    "            vocab.add(word)\n",
    "    return sorted(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "azdata_cell_guid": "c82b93b2-09b1-466f-881b-5c2730b57388",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Pull trainingTokens into one vocabulary listed, no nested arrays\n",
    "\n",
    "vocabulary = getVocab(trainingTokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "azdata_cell_guid": "c1fa23a6-2e9d-423f-b7e1-b3fb64d422be"
   },
   "source": [
    "We can peek at our vocabulary list, an alphabetically sorted list of words, now at a random set of indices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "azdata_cell_guid": "582421f1-1e8c-4e5b-9bee-a84b742b7a6a",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['amount',\n",
      " 'an',\n",
      " 'and',\n",
      " 'angry',\n",
      " 'another',\n",
      " 'anticipated',\n",
      " 'any',\n",
      " 'anything',\n",
      " 'anytime',\n",
      " 'anyway',\n",
      " 'apologize',\n",
      " 'app',\n",
      " 'appalling',\n",
      " 'appetizers',\n",
      " 'apple',\n",
      " 'approval',\n",
      " 'are',\n",
      " 'area',\n",
      " 'aren',\n",
      " 'aria']\n"
     ]
    }
   ],
   "source": [
    "#collapse-hide\n",
    "\n",
    "pprint(vocabulary[50:70])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "azdata_cell_guid": "93e3c874-f1dc-45b8-9c3e-a1cbaf760660"
   },
   "source": [
    "We want our arrays to actually be proper vectors to feed to our model, which we'll create below as well. This function, ```createVector``` transforms our arrays into vectors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "azdata_cell_guid": "f25af79b-16e4-49b7-acec-18f489f356a6"
   },
   "outputs": [],
   "source": [
    "def createVector(vocab, sentences):\n",
    "    indices = []\n",
    "    wordOccurrences = []\n",
    "\n",
    "    for sentenceIndex, sentence in enumerate(sentences):\n",
    "        alreadyCounted = set() # Keep track of words so we don't double count.\n",
    "        for word in sentence:\n",
    "            if (word in vocab) and word not in alreadyCounted:\n",
    "                # If we just want {0,1} for the presence of the word (bernoulli NB),\n",
    "                # only count each word once. Otherwise (multinomial NB) count each\n",
    "                # occurrence of the word.\n",
    "                \n",
    "            \n",
    "                #which sentence, which word\n",
    "                indices.append((sentenceIndex, vocab.index(word)))\n",
    "                \n",
    "                wordOccurrences.append(1)\n",
    "                alreadyCounted.add(word)\n",
    "\n",
    "    # Unzip\n",
    "    rows = [row for row, _ in indices]\n",
    "    columns = [column for _, column in indices]\n",
    "\n",
    "    sentenceVectors = sparse.csr_matrix((wordOccurrences, (rows, columns)), dtype=int, shape=(len(sentences), len(vocab)))\n",
    "\n",
    "    return sentenceVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "azdata_cell_guid": "a1683930-c447-4f33-ba91-4a8c3f55ea6e"
   },
   "outputs": [],
   "source": [
    "training = createVector(vocabulary, trainingTokens)\n",
    "testing = createVector(vocabulary, testingTokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "azdata_cell_guid": "4bbb4757-1f81-4a1c-8341-9879a215fbea"
   },
   "source": [
    "Our training and test data has gone through some transformation. Here's what the training data looks like now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "azdata_cell_guid": "95527d26-176d-41d6-b90a-3aca0ec7421d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data:\n",
      "  (0, 694)\t1\n",
      "  (0, 884)\t1\n",
      "  (0, 1186)\t1\n",
      "  (0, 1335)\t1\n",
      "  (1, 52)\t1\n",
      "  (1, 640)\t1\n",
      "  (1, 768)\t1\n",
      "  (1, 788)\t1\n",
      "  (1, 1158)\t1\n",
      "  (1, 1166)\t1\n",
      "  (1, 1171)\t1\n",
      "  (1, 1281)\t1\n"
     ]
    }
   ],
   "source": [
    "#collapse-hide\n",
    "\n",
    "print(\"Training data:\")\n",
    "print(training[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "azdata_cell_guid": "17e17740-7130-4387-93ae-882b87c03e80"
   },
   "source": [
    "# A Naive Bayes model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "azdata_cell_guid": "750df53a-3c17-48ae-a977-7199732afc21"
   },
   "source": [
    "## Creating and Training our Model\n",
    "\n",
    "Below is our Naive Bayes classifier, which is the model we've chosen to use for our sentiment analysis of restaurant reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "azdata_cell_guid": "17220d70-73b4-4fe6-a5e4-b4ba2dd08e59",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class NaiveBayesClassifier:\n",
    "    def __init__(self):\n",
    "        self.priorPositive = None  # Probability that a review is positive\n",
    "        self.priorNegative = None  # Probability that a review is negative\n",
    "        self.positiveLogConditionals = None\n",
    "        self.negativeLogConditionals = None\n",
    "\n",
    "    def computePriorProbabilities(self, labels):\n",
    "        self.priorPositive = len([y for y in labels if y == 1]) / len(labels)\n",
    "        self.priorNegative = 1 - self.priorPositive\n",
    "\n",
    "    def computeConditionProbabilities(self, examples, labels, dirichlet=1):\n",
    "        _, vocabularyLength = examples.shape\n",
    "\n",
    "        # How many of each word are there in all of the positive reviews\n",
    "        positiveCounts = np.array([dirichlet for _ in range(vocabularyLength)])\n",
    "        # How many of each word are there in all of the negative reviews\n",
    "        negativeCounts = np.array([dirichlet for _ in range(vocabularyLength)])\n",
    "\n",
    "        # Here's how to iterate through a spare array\n",
    "        coordinates = examples.tocoo()  # Converted to a `coordinate` format\n",
    "        for exampleIndex, featureIndex, observationCount in zip(coordinates.row, coordinates.col, coordinates.data):\n",
    "            # For sentence {exampleIndex}, for word at index {featureIndex}, the word occurred {observationCount} times\n",
    "            if labels[exampleIndex] == 1:\n",
    "                positiveCounts[featureIndex] += observationCount\n",
    "            else:\n",
    "                negativeCounts[featureIndex] += observationCount\n",
    "\n",
    "        # [!] Make sure to use the logs of the probabilities\n",
    "        positiveReviewCount = len([y for y in labels if y == 1])\n",
    "        negativeReviewCount = len([y for y in labels if y == 0])\n",
    "\n",
    "        # We are using bernoulli NB (single occurance of a word)\n",
    "        self.positiveLogConditionals = np.log(positiveCounts) - np.log(positiveReviewCount + dirichlet*2)\n",
    "        self.negativeLogConditionals = np.log(negativeCounts) - np.log(negativeReviewCount + dirichlet*2)\n",
    "\n",
    "        # This works for multinomial NB (multiple occurances of a word)\n",
    "        # self.positiveLogConditionals = np.log(positiveCounts) - np.log(sum(positiveCounts))\n",
    "        # self.negativeLogConditionals = np.log(negativeCounts) - np.log(sum(negativeCounts))\n",
    "\n",
    "    # Calculate all of the parameters for making a naive bayes classification\n",
    "    def fit(self, trainingExamples, trainingLabels):\n",
    "        # Compute the probability of positive/negative review\n",
    "        self.computePriorProbabilities(trainingLabels)\n",
    "\n",
    "        # Compute\n",
    "        self.computeConditionProbabilities(trainingExamples, trainingLabels)\n",
    "\n",
    "    def computeLogPosteriors(self, sentence):\n",
    "        return ((np.log(self.priorPositive) + sum(sentence * self.positiveLogConditionals)),\n",
    "                (np.log(self.priorNegative) + sum(sentence * self.negativeLogConditionals)))\n",
    " \n",
    "    # Have the model try predicting if a review if positive or negative\n",
    "    def predict(self, examples):\n",
    "        totalReviewCount, _ = examples.shape\n",
    "        conf_list = []\n",
    "\n",
    "        predictions = np.array([0 for _ in range(totalReviewCount)])\n",
    "\n",
    "        for index, sentence in enumerate(examples):\n",
    "            logProbabilityPositive, logProbabilityNegative = self.computeLogPosteriors(\n",
    "                sentence)\n",
    "            conf_list.append([np.exp(logProbabilityPositive), np.exp(logProbabilityNegative)])\n",
    "            predictions[index] = 1 if logProbabilityPositive > logProbabilityNegative else 0\n",
    "\n",
    "        return conf_list, predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "azdata_cell_guid": "168fc97b-dd2a-46cf-8e79-3934ca77e2b3"
   },
   "source": [
    "Initialize an instance of model and begin to fit the model with our training data and corresponding labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "azdata_cell_guid": "65960622-8f88-49d2-aebe-53ffce20d0bb"
   },
   "outputs": [],
   "source": [
    "nbClassifier = NaiveBayesClassifier()\n",
    "nbClassifier.fit(training, trainingLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "azdata_cell_guid": "15eea9e6-790e-4ada-bd84-26de239c8295"
   },
   "outputs": [],
   "source": [
    "# determine the accuracy of our model\n",
    "\n",
    "def accuracy(predictions, actual):\n",
    "    return sum((predictions == actual)) / len(actual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "azdata_cell_guid": "53d3f21a-63f5-4f29-b7bf-ae1a888370c9"
   },
   "source": [
    "Let's take our model for a spin, using both the training set and the testing set. You may notice discrepencies in accuracy between training and testing - _why is that_?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "azdata_cell_guid": "48ca6a8b-5d89-44f0-a018-78a890bb1916"
   },
   "outputs": [],
   "source": [
    "# run our training and test using the Naive Bayes classifier\n",
    "\n",
    "train_confidence_scores, trainingPredictions = nbClassifier.predict(training)\n",
    "test_confidence_scores, testingPredictions = nbClassifier.predict(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "azdata_cell_guid": "4abd7d0b-f009-4fcb-bbcf-92ef339ffa73",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.9519038076152304\n",
      "Testing accuracy: 0.7947686116700201\n"
     ]
    }
   ],
   "source": [
    "#collapse-hide\n",
    "print(\"Training accuracy:\", accuracy(trainingPredictions, trainingLabels))\n",
    "print(\"Testing accuracy:\", accuracy(testingPredictions, testingLabels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "azdata_cell_guid": "8ad9abfb-46b3-4a23-a3a7-f13924cf2aac"
   },
   "source": [
    "## Visualizing Results\n",
    "\n",
    "Here's another to visualize our results using a confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "azdata_cell_guid": "04e2d67d-41a2-47a5-9504-6b8a02cd331a",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#collapse-hide\n",
    "\n",
    "data = {'Actual':    testingLabels,\n",
    "        'Predicted': testingPredictions\n",
    "        }\n",
    "\n",
    "df = pd.DataFrame(data, columns=['Actual','Predicted'])\n",
    "confusion_matrix = pd.crosstab(df['Actual'], df['Predicted'], rownames=['Actual'], colnames=['Predicted'])\n",
    "\n",
    "ax = sns.heatmap(confusion_matrix, annot=True,cmap=\"YlGnBu\", fmt='d')\n",
    "ax.set_ylim(2.0, 0)\n",
    "\n",
    "plt.title('Confusion Matrix of Testing')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "azdata_cell_guid": "03641042-6d20-485f-af4f-cb781092da6a"
   },
   "source": [
    "## A Closer Look \n",
    "\n",
    "Let's look at the general results for our model - notably, we can look at its precision for predicting negative and positive sentiment in a given sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "azdata_cell_guid": "a8f1107c-edf7-434e-b4bf-9357b2d39e9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      0.91      0.82       251\n",
      "    positive       0.88      0.68      0.77       246\n",
      "\n",
      "    accuracy                           0.79       497\n",
      "   macro avg       0.81      0.79      0.79       497\n",
      "weighted avg       0.81      0.79      0.79       497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = ['negative', 'positive']\n",
    "print(classification_report(testingLabels, testingPredictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "azdata_cell_guid": "d9da7c80-9581-4910-a39c-233435906799"
   },
   "source": [
    "Now, we want to make an interactive confusion matrix so we can precisely see which results are accurately classified and which are mis-classified, as well as the confidence at which the model has classified that result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "azdata_cell_guid": "8341b403-049a-4deb-935a-0007ffb43f90",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# collapse-hide\n",
    "\n",
    "# work with the model results to create a JSON dump of the data for future use\n",
    "\n",
    "import json\n",
    "\n",
    "output_filename = \"predict.json\"\n",
    "data = []\n",
    "for i in range(len(testingPredictions)):\n",
    "  data.append({\n",
    "      'index': i,\n",
    "      'true_label': int(testingLabels[i]),\n",
    "      'predicted_label': int(testingPredictions[i]),\n",
    "      'confidence_score': test_confidence_scores[i],\n",
    "      'text': testingSentences[i]\n",
    "  })\n",
    "\n",
    "with open(output_filename, 'w') as outfile:\n",
    "    json.dump(data, outfile, indent=4, sort_keys=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "import libraries.mlvislib as mlvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script src=\"https://d3js.org/d3.v3.min.js\" charset=\"utf-8\"></script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "\t\t<style> \n",
       "\t\tbody {\n",
       "\t\t    font-family: Arial, sans-serif;\n",
       "\t\t    font-size: larger;\n",
       "\t\t}\n",
       "\t\t.box_highlighted { \n",
       "\t\t    background-color: #ffb; \n",
       "\t\t    border: 1px solid #b53;\n",
       "\t\t}\n",
       "\t\t.highlight{\n",
       "\t\t    background-color: yellow;\n",
       "\t\t}\n",
       "\t\t.lighthigh{\n",
       "\t\t    background-color: green;\n",
       "\t\t}\n",
       "\t\tli{\n",
       "\t\t    font-size: smaller;\n",
       "\t\t}\n",
       "\t\ttd{\n",
       "\t\t    min-width: 100px;\n",
       "\t\t}\n",
       "\t\t#review{\n",
       "\t\t    border:1px solid pink; \n",
       "\t\t    padding: 5px; \n",
       "\t\t    float: left; \n",
       "\t\t    width: 750px; \n",
       "\t\t    height: 500px; \n",
       "\t\t    background-color: white;\n",
       "\t\t    margin: 20px;\n",
       "\t\t    overflow: scroll;\n",
       "\t\t    }\n",
       "\n",
       "\t\t#matrix{\n",
       "\t\t    border:1px solid pink; \n",
       "\t\t    padding: 5px; \n",
       "\t\t    float: left;\n",
       "\t\t    margin: 20px;\n",
       "\t\t}\n",
       "\n",
       "\n",
       "\t\t#slider {\n",
       "\t\t  -webkit-appearance: none;\n",
       "\t\t  width: 100%;\n",
       "\t\t  height: 15px;\n",
       "\t\t  border-radius: 5px;  \n",
       "\t\t  background: #d3d3d3;\n",
       "\t\t  outline: none;\n",
       "\t\t  opacity: 0.7;\n",
       "\t\t  -webkit-transition: .2s;\n",
       "\t\t  transition: opacity .2s;\n",
       "\t\t}\n",
       "\n",
       "\t\t#slider::-webkit-slider-thumb {\n",
       "\t\t  -webkit-appearance: none;\n",
       "\t\t  appearance: none;\n",
       "\t\t  width: 25px;\n",
       "\t\t  height: 25px;\n",
       "\t\t  border-radius: 50%; \n",
       "\t\t  background: #4ca2af;\n",
       "\t\t  cursor: pointer;\n",
       "\t\t}\n",
       "\n",
       "\t\t#slider::-moz-range-thumb {\n",
       "\t\t  width: 25px;\n",
       "\t\t  height: 25px;\n",
       "\t\t  border-radius: 50%;\n",
       "\t\t  background: #4ca2af;\n",
       "\t\t  cursor: pointer;\n",
       "\t\t}\n",
       "\t\t </style>\n",
       "\t\t<h1> Interactive Confusion Matrix </h1>\n",
       "\t\t<input id=\"slider\" type=\"range\" min=\"0\" max=\"1\" step=\".1\" value=\".5\"/>\n",
       "\t\t<div>\n",
       "\t\t<h2 id=\"textInput\"> 0.5 </h2>\n",
       "\t\t<div>\n",
       "\n",
       "\t\t<div id=\"matrix\"> </div>\n",
       "\t\t<div id=\"review\">\n",
       "\t\t\tData \n",
       "\t\t\t<ul id = \"testList\"></ul>\n",
       "\t\t</div>\n",
       "\t\t<script> \n",
       "\t\tconsole.log(\"Loading JavaScript...\")\n",
       "\n",
       "\t\tconsole.log(\"Loaded Data:\")\n",
       "\t\td3.json( \"predict.json\", function(d) {\n",
       "\t\t    console.log(d)\n",
       "\t\t})\n",
       "\n",
       "\t\t/* I've temporarily left out the 'getType' function, since the names of these\n",
       "\t\ttypes are not included in the JSON file that is given to the JavaScript. More functionality can be incldued later to bring the names in as well as the raw data. Type will be represented by the given numeric identifier for now. */\n",
       "\n",
       "\t\t/* extractTypes: identifies different types each data point can be identified\n",
       "\t\tas, based off of the 'true_label' attribute in JSON file\n",
       "\t\tgiven: JSON file\n",
       "\t\treturns: dictionary of possible values for 'true_label' */\n",
       "\t\tfunction extractTypes(data){\n",
       "\t\t    var lookup = {};\n",
       "\t\t    var items = data\n",
       "\t\t    var result = [];\n",
       "\n",
       "\t\t    for (var item, i=0; item = items[i++];){\n",
       "\t\t        var name = item.true_label;\n",
       "\n",
       "\t\t        if(!(name in lookup)){\n",
       "\t\t            lookup[name] = 1;\n",
       "\t\t            result.push(name);\n",
       "\t\t        }\n",
       "\t\t    }\n",
       "\n",
       "\t\t    return lookup;\n",
       "\t\t}\n",
       "\n",
       "\t\td3.select(\"#slider\").on(\"change\", function() {\n",
       "\t\t    d3.select(\"svg\").remove()\n",
       "\t\t    var currentValue = this.value;\n",
       "\t\t    d3.select(\"#textInput\").text(currentValue)\n",
       "\t\t    d3.json(\"predict.json\", function(d) {\n",
       "\t\t        console.log(d); // Ensuring that data is properly read in.\n",
       "\t\t        console.log(Object.keys(extractTypes(d))); // Logging list of possible types\n",
       "\n",
       "\t\t        // # of Categories x # of Categories Table\n",
       "\t\t        tableDimension = Object.keys(extractTypes(d)).length\n",
       "\t\t        var table = new Array(tableDimension);\n",
       "\t\t        var dataset = [];\n",
       "\t\t        for(var i=0; i<tableDimension; i++){\n",
       "\t\t            table[i] = new Array(tableDimension);\n",
       "\t\t            for(var j=0; j<tableDimension; j++){\n",
       "\t\t                table[i][j] = 0;\n",
       "\t\t            }\n",
       "\t\t        }\n",
       "\n",
       "\t\t        // Filling out table with prediction counts and recording dataset\n",
       "\t\t        /* Code is currently dependent on JSON having the data points: \n",
       "\t\t        \"true_label\" and \"predicted_label\" */\n",
       "\t\t        for(var i=0; i<d.length; i+=1){ // i+=1 or i++ ?\n",
       "\t\t            var ugh = d[i][\"confidence_score\"][0];\n",
       "\t\t            console.log(ugh)\n",
       "\t\t            if (ugh < currentValue ){\n",
       "\t\t                table[parseInt(d[i][\"true_label\"])][parseInt(d[i][\"predicted_label\"])]+=1;\n",
       "\t\t                dataset.push([d[i][\"true_label\"], d[i][\"predicted_label\"], d[i][\"text\"], d[i][\"index\"]]);\n",
       "\t\t            }\n",
       "\t\t        }\n",
       "\n",
       "\t\t        console.log(table); // Reporting current state of table values.\n",
       "\n",
       "\t\t        var w = 750;\n",
       "\t\t        var h = 700; // These are dimensions?\n",
       "\n",
       "\t\t        // Create SVG element\n",
       "\t\t        var svg = d3.select(\"body\") // This could be problematic later\n",
       "\t\t                    .select(\"#matrix\")\n",
       "\t\t                    .append(\"svg\")\n",
       "\t\t                    .attr(\"width\", w)\n",
       "\t\t                    .attr(\"height\", h);\n",
       "\n",
       "\t\t        var rect = svg.selectAll(\"rect\")\n",
       "\t\t                      .data(dataset)\n",
       "\t\t                      .enter()\n",
       "\t\t                      .append(\"rect\");\n",
       "\n",
       "\t\t        // Give these a more descriptive name later\n",
       "\t\t        var counters = new Array(tableDimension * tableDimension).fill(0);\n",
       "\t\t        var ycounters = new Array(tableDimension * tableDimension).fill(0);\n",
       "\n",
       "\t\t        var confusing = h / tableDimension;\n",
       "\n",
       "\t\t        // JSON Object Format Guide: \n",
       "\t\t        // d[0] = true_label ; d[1] = predicted_label ; d[2] = text\n",
       "\t\t        rect.attr(\"x\", function (d, i){\n",
       "\t\t            var matrixnum = (parseInt(d[1]) * tableDimension) + parseInt(d[0]);\n",
       "\t\t            var inmatrixcol = counters[matrixnum] % 16;\n",
       "\n",
       "\t\t            counters[matrixnum]++;\n",
       "\n",
       "\t\t            return 10 + (d[0] * confusing) + (inmatrixcol * 16);\n",
       "\n",
       "\t\t            })\n",
       "\t\t            .attr(\"y\", function(d, i){\n",
       "\t\t                var matricvol = d[1];\n",
       "\t\t                var matrixnum = (parseInt(d[1] * tableDimension) + parseInt(d[0]));\n",
       "\t\t                var hm = Math.floor(ycounters[matrixnum]/16);\n",
       "\n",
       "\t\t                ycounters[matrixnum]++;\n",
       "\n",
       "\t\t                return 10 + (d[1] * confusing) + (hm * 16);\n",
       "\t\t            })\n",
       "\t\t            .attr(\"id\", function(d){\n",
       "\t\t                return \"rect\" + d[3];\n",
       "\t\t            })\n",
       "\t\t            .attr(\"width\", function(d){\n",
       "\t\t                return 15;\n",
       "\t\t            })\n",
       "\t\t            .attr(\"height\", function(d){\n",
       "\t\t                return 15;\n",
       "\t\t            })\n",
       "\t\t            .attr(\"opacity\", function(d){\n",
       "\t\t                return .85;\n",
       "\t\t            })\n",
       "\t\t            .attr(\"fill\", function(d){\n",
       "\t\t                return (\"pink\");\n",
       "\t\t            })\n",
       "\t\t            .attr(\"class\", function(d){\n",
       "\t\t                predicted_label = \"predicted_label_\" + d[1];\n",
       "\t\t                true_label = \"true_label_\" + d[0];\n",
       "\n",
       "\t\t                return true_label + \" \" + predicted_label;\n",
       "\t\t        });\n",
       "\n",
       "\t\t        d3.select(\"#review\")\n",
       "\t\t            .select(\"testList\")\n",
       "\t\t            .selectAll(\"rect\")\n",
       "\t\t            .data(\n",
       "\t\t                dataset.filter(d => d[0] != d[1]),\n",
       "\t\t                function(d){\n",
       "\t\t                    return d[3];\n",
       "\t\t                }\n",
       "\t\t            )\n",
       "\t\t            .enter()\n",
       "\t\t            .append(\"li\")\n",
       "\t\t            .attr(\"id\", function(d){\n",
       "\t\t                return \"text\" + d[3];\n",
       "\t\t            })\n",
       "\t\t            .html(function(d){\n",
       "\t\t                table = \"<table><tr>\"\n",
       "\n",
       "\t\t                table += \"<td> True: \";\n",
       "\t\t                table += parseInt(d[0]); //getType(d[0]);\n",
       "\t\t                table += \"</td>\"\n",
       "\n",
       "\t\t                table += \"<td> Predict: \";\n",
       "\t\t                table += parseInt(d[1]); //getType(d[1]);\n",
       "\t\t                table += \"</td>\"\n",
       "\n",
       "\t\t                table += \"<td>\" + d[2].substr(0,200); + \"</td>\"\n",
       "\t\t                table += \"</tr> </table>\"\n",
       "\n",
       "\t\t                return  table;\n",
       "\t\t        });\n",
       "\n",
       "\t\t        rect.on(\"click\", function(d_on){\n",
       "\t\t            d3.select(\"#review\")\n",
       "\t\t                .select(\"#testList\")\n",
       "\t\t                .html(\"\");\n",
       "\n",
       "\t\t            if(!this.classList.contains(\"past\")){\n",
       "\t\t                d3.selectAll(\".past\")\n",
       "\t\t                    .attr(\"fill\", \"pink\")\n",
       "\t\t                    .classed(\"past\", false);\n",
       "\n",
       "\t\t                d3.selectAll(\".reclick\")\n",
       "\t\t                    .attr(\"fill\", \"pink\")\n",
       "\t\t                    .classed(\"reclick\", false)\n",
       "\t\t            }\n",
       "\n",
       "\t\t            if(!this.classList.contains(\"reclick\")){\n",
       "\t\t                d3.selectAll(\".reclick\")\n",
       "\t\t                    .attr(\"fill\", \"pink\")\n",
       "\t\t                    .classed(\"reclick\", false);\n",
       "\t\t            }\n",
       "\n",
       "\t\t            d3.select(this);\n",
       "\n",
       "\t\t            textId = \"\";\n",
       "\t\t            x = \".\" + this.classList[0];\n",
       "\t\t            y = \".\" + this.classList[1];\n",
       "\t\t            test = x + y;\n",
       "\n",
       "\t\t            x1 = x.charAt(x.length - 1);\n",
       "\t\t            y1 = y.charAt(y.length - 1);\n",
       "\n",
       "\t\t            if(this.classList.contains(\"past\")){\n",
       "\t\t                d3.select(this)\n",
       "\t\t                    .classed(\"reclick\", true)\n",
       "\t\t                Id = this.id;\n",
       "\t\t                textId = \"#text\" + Id.substring(4);\n",
       "\t\t            }\n",
       "\n",
       "\t\t            d3.selectAll(test)\n",
       "\t\t                .attr(\"fill\", \"purple\")\n",
       "\t\t                .classed(\"past\", \"true\");\n",
       "\n",
       "\t\t            d3.select(\"#review\")\n",
       "\t\t                .select(\"#testList\")\n",
       "\t\t                .selectAll(\"rect\")\n",
       "\t\t                .data(\n",
       "\t\t                    dataset\n",
       "\t\t                        .filter(d => d[0] == x1)\n",
       "\t\t                        .filter(d => d[1] == y1),\n",
       "\t\t                        function(d){\n",
       "\t\t                            return d[3];\n",
       "\t\t                        }\n",
       "\t\t                )\n",
       "\t\t                .enter()\n",
       "\t\t                .append(\"li\")\n",
       "\t\t                .attr(\"id\", function(d){\n",
       "\t\t                    return \"text\" + d[3];\n",
       "\t\t                })\n",
       "\t\t                .html(function(d){\n",
       "\t\t                    table = \"<table><tr>\"\n",
       "\n",
       "\t\t                    table += \"<td> True: \";\n",
       "\t\t                    table += parseInt(d[0]); //getType(d[0]);\n",
       "\t\t                    table += \"</td>\"\n",
       "\n",
       "\t\t                    table += \"<td> Predict: \";\n",
       "\t\t                    table += parseInt(d[1]); //getType(d[1]);\n",
       "\t\t                    table += \"</td>\"\n",
       "\n",
       "\t\t                    table += \"<td>\" + d[2].substr(0,200); + \"</td>\"\n",
       "\t\t                    table += \"</tr> </table>\"\n",
       "\n",
       "\t\t                    return table;\n",
       "\t\t            });\n",
       "\n",
       "\t\t            d3.select(\"#review\")\n",
       "\t\t                .select(\"testList\")\n",
       "\t\t                .selectAll(\"li\")\n",
       "\t\t                .on(\"mouseover\", function(d_on){\n",
       "\t\t                    d3.select(this)\n",
       "\t\t                        .classed(\"lighthigh\", true)\n",
       "\t\t                        id = this.id;\n",
       "\t\t                        rectId = \"#rect\" + id.substring(4);\n",
       "\t\t                        d3.selectAll(rectId)\n",
       "\t\t                            .attr(\"fill\", \"green\");\n",
       "\t\t                })\n",
       "\t\t                .on(\"mouseout\", function(d_on){\n",
       "\t\t                    d3.select(this)\n",
       "\t\t                        .classed(\"lighthigh\", false)\n",
       "\t\t                        id = this.id;\n",
       "\t\t                        rectId = \"#rect\" + id.substring(4);\n",
       "\t\t                        d3.selectAll(rectId)\n",
       "\t\t                            .attr(\"fill\", \"purple\");\n",
       "\t\t            });\n",
       "\t\t        });\n",
       "\n",
       "\t\t        d3.select(\"#review\")\n",
       "\t\t            .select(\"#testList\")\n",
       "\t\t            .selectAll(\"li\")\n",
       "\t\t            .on(\"mouseover\", function(d_on){\n",
       "\t\t                d3.select(this)\n",
       "\t\t                    .classed(\"lighthigh\", true)\n",
       "\t\t                    id = this.id;\n",
       "\t\t                    rectId = \"#rect\" + id.substring(4);\n",
       "\t\t                    d3.selectAll(rectId)\n",
       "\t\t                        .attr(\"fill\", \"green\");\n",
       "\t\t            })\n",
       "\t\t          .on(\"mouseout\", function(d_on){\n",
       "\t\t                d3.select(this)\n",
       "\t\t                    .classed(\"lighthigh\", false)\n",
       "\t\t                    id = this.id;\n",
       "\t\t                    rectId = \"#rect\" + id.substring(4);\n",
       "\t\t                    d3.selectAll(rectId)\n",
       "\t\t                        .attr(\"fill\", \"pink\");\n",
       "\t\t        });\n",
       "\t\t    });\n",
       "\t\t})\n",
       "\t\t </script>\n",
       "\t\t"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This is an incomplete proof of concept. Data is being directly referenced in the library,\n",
    "# and is not being passed over to the ConfusionMatrix object. \n",
    "cm = mlvs.ConfusionMatrix()\n",
    "cm.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "04f327f8729c4dfb8064560e564bc0c6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ButtonStyleModel",
      "state": {}
     },
     "527b16c6484f41a8bbea8b6f91ee4137": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ButtonStyleModel",
      "state": {}
     },
     "55400c05e9674a448f4e1fca689799eb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ButtonStyleModel",
      "state": {}
     },
     "6d2c241530244303bf40c0e3b075e4ce": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "876403260ccd4a0a8d22c264a6912605": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "91e9ccd185a845428527d57ccb73fb26": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "9f021bc8541a4b19862488ae989a54bf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ButtonModel",
      "state": {
       "description": "Model Accuracy",
       "layout": "IPY_MODEL_dd9515246a5c4b2c8378751eaa36df79",
       "style": "IPY_MODEL_04f327f8729c4dfb8064560e564bc0c6"
      }
     },
     "9f1a03a9c53344238bee47b914fa8692": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ButtonModel",
      "state": {
       "description": "Click to see Vocab",
       "layout": "IPY_MODEL_876403260ccd4a0a8d22c264a6912605",
       "style": "IPY_MODEL_527b16c6484f41a8bbea8b6f91ee4137"
      }
     },
     "dd9515246a5c4b2c8378751eaa36df79": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "eec603a2a46d48bfbb6570ddefcc6477": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ButtonModel",
      "state": {
       "description": "Model Accuracy",
       "layout": "IPY_MODEL_91e9ccd185a845428527d57ccb73fb26",
       "style": "IPY_MODEL_f8efef0d43ab4f32b7ab103f009ffe3b"
      }
     },
     "f7141bc2f4b84b2daf37332f22af3d8f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ButtonModel",
      "state": {
       "description": "Click to see Vocab",
       "layout": "IPY_MODEL_6d2c241530244303bf40c0e3b075e4ce",
       "style": "IPY_MODEL_55400c05e9674a448f4e1fca689799eb"
      }
     },
     "f8efef0d43ab4f32b7ab103f009ffe3b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ButtonStyleModel",
      "state": {}
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
